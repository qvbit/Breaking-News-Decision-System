{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import functools\n",
    "import collections\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_pickle('merged.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'m_size': [2000, 5000, 10000],\n",
    "#               'test_size': [0.2],\n",
    "#               'vector_size': [200, 400, 600],\n",
    "#               'min_count': [2],\n",
    "#               'epochs': [20],\n",
    "#               'window': [5, 10, 15],\n",
    "#               'steps': [1, 20]\n",
    "#              }\n",
    "\n",
    "params = {'m_size': [10000],\n",
    "         'test_size': [0.2],\n",
    "         'vector_size': [400],\n",
    "         'min_count': [2],\n",
    "         'epochs': [20],\n",
    "         'window': [10], \n",
    "         'steps': [20]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleData(df, m_size):\n",
    "    \"\"\"\n",
    "    Sample the data with hyperparameter m_size specifying how many training examples we want\n",
    "    Hyperparameters: m_size\n",
    "    \n",
    "    :param df: Input Pandas DataFrame\n",
    "    :type df: pd.DataFrame\n",
    "    :param m_size: Number of training examples desired\n",
    "    :type m_size: int\n",
    "    \n",
    "    :return: X, y of combined sampled training data and labels for the model\n",
    "    :rtype: List*2\n",
    "    \"\"\"\n",
    "    \n",
    "    pos = df[df['label'] == 1]\n",
    "    neg = df[df['label'] == 0].sample(m_size, random_state=42)\n",
    "    data = neg.append(pos)\n",
    "    combined = [(h + ' ' + s + ' ' + b, l) for h, s, b, l in \n",
    "                    zip(list(data['headline_x']), list(data['summary_x']), list(data['body_x']), list(data['label']))]\n",
    "    print('Sampling Done')\n",
    "    return zip(*combined)\n",
    "\n",
    "\n",
    "\n",
    "def stratSpl(X, y, test_size):\n",
    "    \"\"\"\n",
    "    Make a stratified test/train split to use for training and testing.\n",
    "    Hyperparameters: None\n",
    "    \n",
    "    :param X: Input features of the combined (train and test) sampled set. \n",
    "    :type X: List\n",
    "    :param y: Input labels of the combined (train and test) sampled set\n",
    "    :type y: List\n",
    "    :param test_size: Test ratio to split up. Number between 0 and 1\n",
    "    :type test_size: Float\n",
    "    \n",
    "    :return: 4 Lists corresponding to X_tr, X_te, y_tr, y_te\n",
    "    :rtype: List*4\n",
    "    \"\"\"\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_tr, X_te = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_tr, y_te = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    \n",
    "    print('Stratified test/train split done')\n",
    "    return X_tr, y_tr, X_te, y_te\n",
    "\n",
    "\n",
    "\n",
    "def read_corpus(data):\n",
    "    \"\"\"\n",
    "    Prepare the data (using gensims simple_preprocess)\n",
    "    Hyperparameters: None\n",
    "    \n",
    "    :param data: Document \n",
    "    :type X_tr: List\n",
    "    \n",
    "    :return: Processed version data.\n",
    "    :rtype: Iterator\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print('Tokenizing data')\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        yield TaggedDocument(simple_preprocess(line), tags=[i])\n",
    "    \n",
    "\n",
    "\n",
    "def doc2vec_model_train(X_tr, vector_size, min_count, epochs, window):\n",
    "    \"\"\"\n",
    "    Doc2Vec model defined and trained via this function. \n",
    "    Hyperparameters: size, min_count, epochs, window\n",
    "    \n",
    "    :param X_tr: Training data\n",
    "    :type X_tr: List\n",
    "    :param vector_size: Dimensionality of the feature vectors \n",
    "    :type vector_size: Int\n",
    "    :param min_count: Minimum occurences for which to still keep a word in the vocab.\n",
    "    :type min_count: Int\n",
    "    :param epochs: Number of epochs for which the model trains\n",
    "    :type epochs: Int\n",
    "    :param window: Window size of context to consider in a given instance.\n",
    "    :type window: Int\n",
    "    \n",
    "    :return: Fully trained model\n",
    "    :rtype: gensim model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Doc2Vec(vector_size=vector_size, min_count=min_count, window=window, epochs=epochs)\n",
    "    model.build_vocab(X_tr)\n",
    "    model.train(X_tr, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    print('Doc2Vec Model Trained')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def embeddings(model, X, steps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Embed documents into vector space for classification in the next stage.\n",
    "    Hyperparameters: steps\n",
    "    \n",
    "    :param model: Trained Doc2Vec model\n",
    "    :type model: gensim Doc2Vec model\n",
    "    :param X: Input corpus\n",
    "    :type X: List of TaggedDocuments\n",
    "    :param steps: Hyperparameter to tune\n",
    "    :type steps: Int\n",
    "    \n",
    "    :return: Embedded feature vector\n",
    "    :rtype: List\n",
    "    \"\"\"\n",
    "    \n",
    "    z = [model.infer_vector(X[doc_id].words, steps=steps) for doc_id in range(len(X))]\n",
    "    \n",
    "    print('Documents embedded into vector space')\n",
    "    \n",
    "    return z\n",
    "\n",
    "\n",
    "def FinalClassifier(X_tr, y_tr):\n",
    "    \n",
    "    \"\"\"\n",
    "    Models for final classifcation, will be hyperparameters\n",
    "    Hyperparameters: The models themselves and their hyperparameters *Come back here for alteration\n",
    "    \n",
    "    :param X_tr: Input document vectors \n",
    "    :type X_tr: List\n",
    "    :param y_tr: Labels\n",
    "    :type: List\n",
    "    \n",
    "    :return: Trained logreg model\n",
    "    :rtype: \n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(random_state=42).fit(X_tr, y_tr)\n",
    "    print('Final Classifier Trained.')\n",
    "    \n",
    "    return clf\n",
    "    \n",
    "    \n",
    "def cross_val(clf, X_tr, y_tr):\n",
    "    \"\"\"\n",
    "    Cross validation on training set. This will be used to score the grid search models and tune hyperparameters.\n",
    "    Hyperparameters: None\n",
    "    \n",
    "    :param clf: Second stage classifier\n",
    "    :type clf: Sklearn (or other) classifier\n",
    "    :param X_tr: Training data emedded doc vectors\n",
    "    :type X_tr: List\n",
    "    :param y_tr: Training labels\n",
    "    :type y_tr: \n",
    "    \n",
    "    \"\"\"\n",
    "    scoring = ['f1', 'precision', 'recall', 'average_precision']\n",
    "    \n",
    "    scores = cross_validate(clf, X_tr, y_tr, cv=3, scoring=scoring)\n",
    "    \n",
    "    print('Cross val scores computed for this set of params.')\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "\n",
    "def precision(conf):\n",
    "    num = conf[0][1]\n",
    "    den = num + conf[1][1]\n",
    "\n",
    "    return num/den\n",
    "\n",
    "def recall(conf):\n",
    "    num = conf[1][1]\n",
    "    den = num + conf[1][0]\n",
    "    \n",
    "    return num/den\n",
    "\n",
    "def F1(P, R):\n",
    "    return 2 * P*R/(P+R)\n",
    "\n",
    "def average(l):\n",
    "    return functools.reduce(lambda x, y: x + y, l) / len(l)\n",
    "\n",
    "def flatten(x):\n",
    "    if isinstance(x, collections.Iterable) and not isinstance(x, tuple) and not isinstance(x, str) and not isinstance(x, dict):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "    else:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_kwargs(**kwargs):\n",
    "    m_size = kwargs.pop('m_size')\n",
    "    test_size = kwargs.pop('test_size')\n",
    "    vector_size = kwargs.pop('vector_size')\n",
    "    min_count = kwargs.pop('min_count')\n",
    "    epochs = kwargs.pop('epochs')\n",
    "    window = kwargs.pop('window')\n",
    "    steps = kwargs.pop('steps')\n",
    "    \n",
    "    return m_size, test_size, vector_size, min_count, epochs, window, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(scores, **kwargs):\n",
    "    \n",
    "    \n",
    "    # Change in case more HP\n",
    "    m_size, test_size, vector_size, min_count, epochs, window, steps = unpack_kwargs(**kwargs)\n",
    "    \n",
    "    X, y = sampleData(merged, m_size)\n",
    "\n",
    "    X_tr, y_tr, _, _ = stratSpl(X, y, test_size)\n",
    "\n",
    "    X_tr = list(read_corpus(X_tr))\n",
    "    \n",
    "    ## start K fold HERE!\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    temp = []\n",
    "    print('Cross validation commencing...')\n",
    "    i = 0\n",
    "    for train_index, test_index in skf.split(X_tr, y_tr):\n",
    "        \n",
    "        print('Split %r...' % i)\n",
    "        \n",
    "        X_tr_cv, X_te_cv = [X_tr[i] for i in train_index], [X_tr[i] for i in test_index]\n",
    "        y_tr_cv, y_te_cv = [y_tr[i] for i in train_index], [y_tr[i] for i in test_index]\n",
    "        \n",
    "        d2v = doc2vec_model_train(X_tr_cv, vector_size, min_count, epochs, window)\n",
    "        \n",
    "        X_tr_cv = embeddings(d2v, X_tr_cv, steps)\n",
    "        \n",
    "        clf = FinalClassifier(X_tr_cv, y_tr_cv)\n",
    "        \n",
    "        X_te_cv = embeddings(d2v, X_te_cv, steps)\n",
    "        \n",
    "        y_pr, y_sc = clf.predict(X_te_cv), clf.decision_function(X_te_cv)\n",
    "        \n",
    "        conf = confusion_matrix(y_te_cv, y_pr)\n",
    "        print(conf)\n",
    "        \n",
    "        p, r = precision(conf), recall(conf)\n",
    "        f1, ap = F1(p, r), average_precision_score(y_te_cv, y_sc)\n",
    "        \n",
    "        temp.append([p, r, f1, ap])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    scores.append(temp)\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking set 0 of parameters...\n",
      "Sampling Done\n",
      "Stratified test/train split done\n",
      "Tokenizing data\n",
      "Cross validation commencing...\n",
      "Split 0...\n",
      "Doc2Vec Model Trained\n",
      "Documents embedded into vector space\n",
      "Final Classifier Trained.\n",
      "Documents embedded into vector space\n",
      "[[1531   69]\n",
      " [  38   47]]\n",
      "Split 1...\n",
      "Doc2Vec Model Trained\n",
      "Documents embedded into vector space\n",
      "Final Classifier Trained.\n",
      "Documents embedded into vector space\n",
      "[[1536   64]\n",
      " [  29   56]]\n",
      "Split 2...\n",
      "Doc2Vec Model Trained\n",
      "Documents embedded into vector space\n",
      "Final Classifier Trained.\n",
      "Documents embedded into vector space\n",
      "[[1547   53]\n",
      " [  29   56]]\n",
      "Split 3...\n",
      "Doc2Vec Model Trained\n",
      "Documents embedded into vector space\n",
      "Final Classifier Trained.\n",
      "Documents embedded into vector space\n",
      "[[1535   65]\n",
      " [  31   53]]\n",
      "Split 4...\n",
      "Doc2Vec Model Trained\n",
      "Documents embedded into vector space\n",
      "Final Classifier Trained.\n",
      "Documents embedded into vector space\n",
      "[[1535   65]\n",
      " [  32   52]]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    \n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))\n",
    "        \n",
    "results = {}\n",
    "scores=[]\n",
    "\n",
    "for i, param in enumerate(list(product_dict(**params))):\n",
    "    print('Checking set %r of parameters...' % i)\n",
    "    \n",
    "    scores = full_pipeline(scores, **param)\n",
    "    \n",
    "    results[i] = flatten([param, list(zip(*scores[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Cross Val Results (all splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model #</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'m_size': 10000, 'test_size': 0.2, 'vector_size': 400, 'min_count': 2, 'epochs': 20, 'window': 10, 'steps': 20}</td>\n",
       "      <td>(0.5948275862068966, 0.5333333333333333, 0.48623853211009177, 0.5508474576271186, 0.5555555555555556)</td>\n",
       "      <td>(0.5529411764705883, 0.6588235294117647, 0.6588235294117647, 0.6309523809523809, 0.6190476190476191)</td>\n",
       "      <td>(0.5731200848281347, 0.5894736842105264, 0.5595249316617965, 0.5881850776848216, 0.5855855855855856)</td>\n",
       "      <td>(0.5248189136573098, 0.6500365275103567, 0.671273841553746, 0.583868009795207, 0.5999321680941284)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model #  \\\n",
       "0  0         \n",
       "\n",
       "                                                                                                         Parameters  \\\n",
       "0  {'m_size': 10000, 'test_size': 0.2, 'vector_size': 400, 'min_count': 2, 'epochs': 20, 'window': 10, 'steps': 20}   \n",
       "\n",
       "                                                                                               Precision  \\\n",
       "0  (0.5948275862068966, 0.5333333333333333, 0.48623853211009177, 0.5508474576271186, 0.5555555555555556)   \n",
       "\n",
       "                                                                                                 Recall  \\\n",
       "0  (0.5529411764705883, 0.6588235294117647, 0.6588235294117647, 0.6309523809523809, 0.6190476190476191)   \n",
       "\n",
       "                                                                                                     F1  \\\n",
       "0  (0.5731200848281347, 0.5894736842105264, 0.5595249316617965, 0.5881850776848216, 0.5855855855855856)   \n",
       "\n",
       "                                                                                    Average Precision  \n",
       "0  (0.5248189136573098, 0.6500365275103567, 0.671273841553746, 0.583868009795207, 0.5999321680941284)  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[key] + [val for val in vals] for key, vals in results.items()]\n",
    "    \n",
    "\n",
    "pr = pd.DataFrame(data, columns=['Model #', 'Parameters', 'Precision', 'Recall',\n",
    "                                 'F1', 'Average Precision'])\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Cross Val Results(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_av = pr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_av['Precision'] = pr_av['Precision'].apply(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_av['Recall'] = pr_av['Recall'].apply(average)\n",
    "pr_av['F1'] = pr_av['F1'].apply(average)\n",
    "pr_av['Average Precision'] = pr_av['Average Precision'].apply(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model #</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'m_size': 10000, 'test_size': 0.2, 'vector_size': 400, 'min_count': 2, 'epochs': 20, 'window': 10, 'steps': 20}</td>\n",
       "      <td>0.54416</td>\n",
       "      <td>0.624118</td>\n",
       "      <td>0.579178</td>\n",
       "      <td>0.605986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model #  \\\n",
       "0  0         \n",
       "\n",
       "                                                                                                         Parameters  \\\n",
       "0  {'m_size': 10000, 'test_size': 0.2, 'vector_size': 400, 'min_count': 2, 'epochs': 20, 'window': 10, 'steps': 20}   \n",
       "\n",
       "   Precision    Recall        F1  Average Precision  \n",
       "0  0.54416    0.624118  0.579178  0.605986           "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
